{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zajęcia 3\n",
    "\n",
    "## Zarządzanie i wdrażanie modeli ML\n",
    "Platform ML Flow (https://www.mlflow.org/docs/latest/index.html) umożliwia całościowe zarządzanie cyklem życia modeli.\n",
    "* logowanie eksperymentów, wartości parametrów modeli i osiąganych przez nie wyników\n",
    "* serializowanie modeli (na potrzeby współdzielenia modelu, przeniesienia na inne środowisko lub serwowania)\n",
    "* wersjonowanie modelu, adnotowanie i przechowywanie w Rejestrze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user_name = os.environ.get('USER')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".config('spark.driver.memory','1g') \\\n",
    ".config('spark.executor.memory', '2g') \\\n",
    ".getOrCreate()\n",
    "\n",
    "gs_path = f'gs://bucket-{user_name}/survey/2020/survey_results_public.csv'\n",
    "db_name = user_name.replace('-','_')\n",
    "spark.sql(f'DROP DATABASE IF EXISTS {db_name} CASCADE')\n",
    "spark.sql(f'CREATE DATABASE {db_name}')\n",
    "spark.sql(f'USE {db_name}')\n",
    "table_name = \"survey_2020\" \n",
    "\n",
    "spark.sql(f'DROP TABLE IF EXISTS {table_name}')\n",
    "\n",
    "spark.sql(f'CREATE TABLE IF NOT EXISTS {table_name} \\\n",
    "          USING csv \\\n",
    "          OPTIONS (HEADER true, INFERSCHEMA true, NULLVALUE \"NA\") \\\n",
    "          LOCATION \"{gs_path}\"')\n",
    "\n",
    "# Przygotowanie danych do analizy\n",
    "\n",
    "spark_df= spark.sql(f'SELECT *, CAST((convertedComp > 60000) AS STRING) AS compAboveAvg \\\n",
    "                    FROM {table_name} WHERE convertedComp IS NOT NULL ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "y = 'compAboveAvg'      # chcemy przewidziec compAboveAvg\n",
    "feature_columns = ['OpSys', 'EdLevel', 'MainBranch' , 'Country', 'JobSeek', 'YearsCode']\n",
    "\n",
    "stringindexer_stages = [StringIndexer(inputCol=c, outputCol='strindexed_' + c).setHandleInvalid(\"keep\") for c in feature_columns]\n",
    "stringindexer_stages += [StringIndexer(inputCol=y, outputCol='label').setHandleInvalid(\"keep\")]\n",
    "\n",
    "onehotencoder_stages = [OneHotEncoder(inputCol='strindexed_' + c, outputCol='onehot_' + c) for c in feature_columns]\n",
    "\n",
    "# Polaczenie wszystkich kolumn predykcyjnych do jednej (features) ASEMBLACJA\n",
    "extracted_columns = ['onehot_' + c for c in feature_columns]\n",
    "vectorassembler_stage = VectorAssembler(inputCols=extracted_columns, outputCol='features') \n",
    "\n",
    "# Polaczenie wszystkich krokow przygotowania danych w jednym potoku przetwarzania\n",
    "final_columns = [y] + feature_columns + extracted_columns + ['features', 'label']\n",
    "\n",
    "transformed_df = Pipeline(stages=stringindexer_stages + \\\n",
    "                          onehotencoder_stages + \\\n",
    "                          [vectorassembler_stage]).fit(spark_df).transform(spark_df).select(final_columns)\n",
    "training, test = transformed_df.randomSplit([0.8, 0.2], seed=1234) # Podzial na zbior treningowy/testowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRZEWO DECYZYJNE - bez parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "dt_model = Pipeline(stages=[dt]).fit(training)\n",
    "pred_dt = dt_model.transform(test)\n",
    "label_and_pred = pred_dt.select('label', 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ewaluacje\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "evaluator_auroc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "evaluator_prec = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_f = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedFMeasure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLFLOW_TRACKING_URI=http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "%env MLFLOW_TRACKING_URI=http://localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mleap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-69703c633f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dt_classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dt_classifier_mleap'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformed_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/jovyan/venv/datascience/lib/python3.7/site-packages/mlflow/spark.py\u001b[0m in \u001b[0;36mlog_model\u001b[0;34m(spark_model, artifact_path, conda_env, dfs_tmpdir, sample_input, registered_model_name, signature, input_example, await_registration_for)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mconda_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0minput_example\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_model_metadata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/jovyan/venv/datascience/lib/python3.7/site-packages/mlflow/spark.py\u001b[0m in \u001b[0;36m_save_model_metadata\u001b[0;34m(dst_dir, spark_model, mlflow_model, sample_input, conda_env, signature, input_example)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdst_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mspark_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0msample_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         )\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/jovyan/venv/datascience/lib/python3.7/site-packages/mlflow/utils/annotations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s only takes keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mnotice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".. Note:: This method requires all argument be specified by keyword.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/jovyan/venv/datascience/lib/python3.7/site-packages/mlflow/mleap.py\u001b[0m in \u001b[0;36madd_to_model\u001b[0;34m(mlflow_model, path, spark_model, sample_input)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipelineModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmleap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmleap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark_support\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleSparkSerializer\u001b[0m  \u001b[0;31m# pylint: disable=unused-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPy4JError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mleap'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"Classifier\")\n",
    "experiment = mlflow.get_experiment_by_name('Classifier')\n",
    "\n",
    "with mlflow.start_run(experiment_id = experiment.experiment_id, run_name=\"dt_model\"):\n",
    "  \n",
    "    mlflow.log_param(\"depth\", dt.getMaxDepth())\n",
    "\n",
    "    test_metric_auroc = evaluator_auroc.evaluate(dt_model.transform(test))\n",
    "    test_metric_acc = evaluator_acc.evaluate(dt_model.transform(test))\n",
    "    test_metric_recall = evaluator_recall.evaluate(dt_model.transform(test))\n",
    "    test_metric_prec = evaluator_prec.evaluate(dt_model.transform(test))\n",
    "    test_metric_f = evaluator_f.evaluate(dt_model.transform(test))\n",
    "\n",
    "    mlflow.log_metric(evaluator_auroc.getMetricName(), test_metric_auroc) \n",
    "    mlflow.log_metric(evaluator_acc.getMetricName(), test_metric_acc) \n",
    "    mlflow.log_metric(evaluator_recall.getMetricName(), test_metric_recall) \n",
    "    mlflow.log_metric(evaluator_prec.getMetricName(), test_metric_prec)     \n",
    "    mlflow.log_metric(evaluator_f.getMetricName(), test_metric_f) \n",
    "  \n",
    "    mlflow.spark.log_model(spark_model=dt_model, artifact_path='dt_classifier')\n",
    "    mlflow.spark.log_model(spark_model=dt_model, artifact_path='dt_classifier_mleap', sample_input=transformed_df) \n",
    "\n",
    "    \n",
    "    # mlflow.mleap.log_model(spark_model=dt_model, artifact_path='dt_classifier_mleap', sample_input=transformed_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drzewo decyzyjne - walidacja krzyżowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "param_grid = ParamGridBuilder().\\\n",
    "    addGrid(dt.maxDepth, [2,3,4,5,6]).\\\n",
    "    build()\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator(estimator=dt, estimatorParamMaps=param_grid, evaluator=evaluator_auroc, numFolds=4)\n",
    "\n",
    "with mlflow.start_run(experiment_id = experiment.experiment_id, run_name=\"best_model\"):\n",
    "    cv_model = cv.fit(training)\n",
    "  \n",
    "    mlflow.log_param(\"depth\", cv_model.bestModel.depth)\n",
    "\n",
    "    test_metric_auroc = evaluator_auroc.evaluate(cv_model.bestModel.transform(test))\n",
    "    test_metric_acc = evaluator_acc.evaluate(cv_model.bestModel.transform(test))\n",
    "    test_metric_recall = evaluator_recall.evaluate(cv_model.bestModel.transform(test))\n",
    "    test_metric_prec = evaluator_prec.evaluate(cv_model.bestModel.transform(test))\n",
    "    test_metric_f = evaluator_f.evaluate(cv_model.bestModel.transform(test))\n",
    "\n",
    "    mlflow.log_metric(evaluator_auroc.getMetricName(), test_metric_auroc) \n",
    "    mlflow.log_metric(evaluator_acc.getMetricName(), test_metric_acc) \n",
    "    mlflow.log_metric(evaluator_recall.getMetricName(), test_metric_recall) \n",
    "    mlflow.log_metric(evaluator_prec.getMetricName(), test_metric_prec)     \n",
    "    mlflow.log_metric(evaluator_f.getMetricName(), test_metric_f) \n",
    "  \n",
    "    mlflow.spark.log_model(spark_model=cv_model.bestModel, artifact_path='best_classifier') \n",
    "    mlflow.mleap.log_model(spark_model=cv_model.bestModel, artifact_path='best_classifier_mleap') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "gbt_model = gbt.fit(training)\n",
    "\n",
    "with mlflow.start_run(experiment_id = experiment.experiment_id, run_name=\"gbt_model\"):\n",
    "  \n",
    "    mlflow.log_param(\"depth\", gbt.getMaxDepth())\n",
    "\n",
    "    test_metric_auroc = evaluator_auroc.evaluate(gbt_model.transform(test))\n",
    "    test_metric_acc = evaluator_acc.evaluate(gbt_model.transform(test))\n",
    "    test_metric_recall = evaluator_recall.evaluate(gbt_model.transform(test))\n",
    "    test_metric_prec = evaluator_prec.evaluate(gbt_model.transform(test))\n",
    "    test_metric_f = evaluator_f.evaluate(gbt_model.transform(test))\n",
    "\n",
    "    mlflow.log_metric(evaluator_auroc.getMetricName(), test_metric_auroc) \n",
    "    mlflow.log_metric(evaluator_acc.getMetricName(), test_metric_acc) \n",
    "    mlflow.log_metric(evaluator_recall.getMetricName(), test_metric_recall) \n",
    "    mlflow.log_metric(evaluator_prec.getMetricName(), test_metric_prec)     \n",
    "    mlflow.log_metric(evaluator_f.getMetricName(), test_metric_f) \n",
    "  \n",
    "    mlflow.spark.log_model(spark_model=gbt_model, artifact_path='gbt_classifier') \n",
    "    mlflow.mleap.log_model(spark_model=gbt_model, artifact_path='gbt_classifier_mleap') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "notebook_test": {
   "keytab_path": "/data/work/home/ds-lab-testuser1/ds-lab-testuser1.keytab",
   "user": "ds-lab-testuser1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
