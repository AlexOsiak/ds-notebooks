{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza i wizualicja danych\n",
    "\n",
    "\n",
    "* wczytanie i transformacja danych\n",
    "* wizualizacje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie danych\n",
    "\n",
    "Bedziemy dzialac na danych na danych z ankiety StackOverflow z 2019.\n",
    "\n",
    "https://insights.stackoverflow.com/survey/\n",
    "\n",
    "Dane sa dostepne na google drive. Nie mozemy tego latwo sciagnac w bashu lub cmdline.\n",
    "Jest dostepny modul wydany google ktory pozwala pobrac dokument o podanym id.\n",
    "\n",
    "Sprobujmy go zainstalowac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz musimy odswiezyc strone zeby zobaczyc nowy kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/data/survey.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path = str(Path.home()) + \"/data/survey.zip\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1QOmVDpd8hcVYqqUXDXf68UMDWQZP0wQV into /home/jovyan/data/survey.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id='1QOmVDpd8hcVYqqUXDXf68UMDWQZP0wQV',\n",
    "                                    dest_path=path,\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZADANIE\n",
    "\n",
    "Zapoznaj sie z plikami tekstowymi, ich wielkosciami. Wgraj plik do katalogu na HDFS /user/{USER}/survey/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls\n",
    "head -2 survey_results_public.csv\n",
    "wc -l survey_results_public.csv\n",
    "cat survey_results_schema.csv\n",
    "hdfs dfs -mkdir -p /user/${USER}/survey/data/\n",
    "hdfs dfs -put -f  survey_results_public.csv /user/${USER}/survey/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stworz tabele z danymi korzystajac z sesji sparkowej\n",
    "skorzystaj ze swojej bazy danych, ktora tworzylismy ostatnio. Tabele nazwijmy survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user_name = os.environ.get('USER')\n",
    "print(user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "port_number = random.randint(4000,4999)\n",
    "print(port_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "source my_env/bin/activate\n",
    "pip install pyspark\n",
    "deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".master('yarn-client') \\\n",
    ".config('spark.driver.memory','1g')\\\n",
    ".config('spark.executor.memory', '1g') \\\n",
    ".config('spark.ui.port', port_number) \\\n",
    ".appName(f'survey_{user_name}') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisanie danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'/user/{user_name}/survey/data/survey_results_public.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = user_name.replace('-','_')\n",
    "table_name = \"survey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"show databases\").show()\n",
    "spark.sql(f'DROP DATABASE IF EXISTS {db_name} CASCADE')\n",
    "spark.sql(f'CREATE DATABASE {db_name} LOCATION \"/edugen/db/{db_name}\"')\n",
    "spark.sql(f'USE {db_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f'DROP TABLE IF EXISTS {table_name}')\n",
    "\n",
    "spark.sql(f'CREATE TABLE IF NOT EXISTS {table_name} \\\n",
    "          USING csv \\\n",
    "          OPTIONS (HEADER true, INFERSCHEMA true) \\\n",
    "          LOCATION \"{path}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weryfikacja danych \n",
    "Sprawdzmy typy danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"describe {table_name}\").show()\n",
    "# nie wszystkie dane ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"describe {table_name}\").show(100)\n",
    "# niepoprawne typy danych... \"NA\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"select distinct Age from {table_name} order by Age desc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsługa wartosci 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f'DROP TABLE IF EXISTS {table_name}')\n",
    "\n",
    "spark.sql(f'CREATE TABLE IF NOT EXISTS {table_name} \\\n",
    "          USING csv \\\n",
    "          OPTIONS (HEADER true, INFERSCHEMA true, NULLVALUE \"NA\") \\\n",
    "          LOCATION \"{path}\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"describe {table_name}\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"select * from {table_name} limit 10\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"select count(*) from {table_name}\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narysuj histogram wieku respondentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = spark.sql(f\"select cast (Age as int) \\\n",
    "                    from {table_name} \\\n",
    "                    where Age is not null \\\n",
    "                    and age between 10 and 80\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.hist(\"Age\", bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ages, bins=10, rug=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ilu jest programistów hobbistów? Jak to wygląda u kobiet a jak u mężczyzn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobby = spark.sql(f\"select Hobbyist,count(*) as cnt from {table_name} group by Hobbyist\").toPandas()\n",
    "hobby_men = spark.sql(f\"select Hobbyist,count(*) as cnt from {table_name} where Gender='Man' group by Hobbyist\").toPandas()\n",
    "hobby_women = spark.sql(f\"select Hobbyist,count(*) as cnt from {table_name} where Gender='Woman' group by Hobbyist\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobby.plot.pie(y='cnt', labels=hobby['Hobbyist'], title=\"All\")\n",
    "plt.legend(loc=\"center left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobby_men.plot.pie(y='cnt', labels=hobby_men['Hobbyist'])\n",
    "plt.legend(loc=\"center left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobby_women.plot.pie(y='cnt', labels=hobby_women['Hobbyist'])\n",
    "plt.legend(loc=\"lower center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "# axes[0]\n",
    "\n",
    "hobby.plot.pie(y='cnt', labels=hobby['Hobbyist'], title=\"All\", ax=axes[0], autopct='%.0f')\n",
    "hobby_men.plot.pie(y='cnt', labels=hobby['Hobbyist'], title=\"Men\", ax=axes[1], autopct='%.0f')\n",
    "hobby_women.plot.pie(y='cnt', labels=hobby['Hobbyist'], title=\"Women\", ax=axes[2], autopct='%.0f')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narysuj wykres zależności między wiekiem a liczbą przepracowanych godzin dla developerów zawodowych w przedziale wiekowym 18-65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_work = spark.sql(f\"Select Age, avg(WorkWeekHrs) as avg from {table_name} \\\n",
    "            where Age is not null and WorkWeekHrs is not null and Age between 18 and 65 and hobbyist = 'No' \\\n",
    "            group by Age \\\n",
    "            order by Age asc\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_work.plot(x='Age', y='avg', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Age\", y=\"avg\", kind=\"line\", data=age_work);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"select distinct DevType from {table_name} where DevType like '%Data scientist%' \").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyswietl wykres słupkowy liczby respondentów na kraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_countries = spark.sql(f\"select country, count(*) as cnt \\\n",
    "                from {table_name} \\\n",
    "                group by Country \\\n",
    "                order by cnt DESC \\\n",
    "                limit 10 \").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_countries.plot.bar(y='cnt', x='country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"country\", y=\"cnt\", kind=\"bar\",\\\n",
    "            data=max_countries)\\\n",
    ".set_xticklabels(rotation=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyswietl średnie zarobki w  krajach w ktorych jest powyzej 1000 respondentow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_salary = spark.sql(f\"select country, \\\n",
    "    cast (avg(ConvertedComp) as int) as avg \\\n",
    "    from {table_name} \\\n",
    "    where country is not null \\\n",
    "    group by country \\\n",
    "    having count(*) > 1000 \\\n",
    "    order by avg desc \\\n",
    "    limit 50 \").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_salary.plot.barh((\"country\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pokaz rozklad pensji w krajach gdzie jest powyzej 1000 respondentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_comp = spark.sql(f\"select country, cast(ConvertedComp as int) \\\n",
    "                from {table_name} \\\n",
    "                where country IN (select country from {table_name} group by country having count(*) > 1000) \\\n",
    "                and ConvertedComp is not null and ConvertedComp > 0\\\n",
    "                order by ConvertedComp desc\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_comp.boxplot(column=\"ConvertedComp\", by=\"country\", \\\n",
    "                     showfliers=False, rot=60, meanline=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"country\", y=\"ConvertedComp\", kind=\"box\", \\\n",
    "            showfliers=False, data=country_comp, palette=\"Blues\")\\\n",
    "    .set_xticklabels(rotation=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZADANIE:\n",
    "Narysuj rozklad pensji w zaleznosci od plci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = spark.sql(f\"select Gender, cast(ConvertedComp as int) as ConvertedComp \\\n",
    "                    from {table_name} where Gender is not null and ConvertedComp is not null \\\n",
    "                    and Gender in ('Man', 'Woman')\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all['Gender'] = df_all['Gender'].replace('Non-binary, genderqueer, or gender non-conforming','Non-binary', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.boxplot(by=\"Gender\", column=\"ConvertedComp\", showfliers=False, rot=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narysuj wykres popularnosci jezykow programowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = spark.sql(f\"select LanguageWorkedWith from {table_name}\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = lang[\"LanguageWorkedWith\"].str.split(';', expand=True)\n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = languages.apply(pd.Series.value_counts)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary2 = pd.DataFrame({'count':summary.sum(axis=1)})\n",
    "summary2.sort_values(\"count\", inplace=True, ascending=True)\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(num=None, figsize=(8, 9), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.barh(width=summary2[\"count\"], y=summary2.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary2['index'] = summary2.index\n",
    "\n",
    "sns.catplot(x=\"index\", y=\"count\", kind=\"bar\", \\\n",
    "             data=summary2, palette=\"Blues\") \\\n",
    ".set_xticklabels(rotation=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narysuj wykres popularnosci jezykow wsrod Data Scientists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lang(df):\n",
    "    languages = df[\"LanguageWorkedWith\"].str.split(';', expand=True)\n",
    "    summary = languages.apply(pd.Series.value_counts)\n",
    "    summary2 = pd.DataFrame({'count':summary.sum(axis=1)})\n",
    "    summary2.sort_values(\"count\", inplace=True, ascending=True)\n",
    "    return summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = spark.sql(f\"select LanguageWorkedWith \\\n",
    "                from {table_name} \\\n",
    "                where DevType like '%Data scientist%'\").toPandas()\n",
    "\n",
    "sum_lang = prepare_lang(lang)\n",
    "\n",
    "\n",
    "figure(num=None, figsize=(8, 9), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.barh(width=sum_lang[\"count\"], y=sum_lang.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "sns.distplot(spark.sql(f\"select Age from {table_name} where Age is not null\").toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wykształcenie... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"select distinct EdLevel from {table_name}\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "ed_level = spark.sql(f\"select EdLevel, WorkWeekHrs from {table_name} \\\n",
    "            where EdLevel is not null and YearsCodePro is not null \\\n",
    "            and cast(WorkWeekHrs as int) is not null \\\n",
    "            and cast(WorkWeekHrs as int) between 10 and 80 \\\n",
    "            and (EdLevel like '%Bachelor%' or EdLevel like '%Master%' or EdLevel like '%Other doctoral%')\")\n",
    "\n",
    "ed_pandas = ed_level.toPandas()\n",
    "ed_pandas['EdLevel'] = ed_pandas['EdLevel'].replace('Bachelor’s degree (BA, BS, B.Eng., etc.)','Bachelor')\n",
    "ed_pandas['EdLevel'] = ed_pandas['EdLevel'].replace('Master’s degree (MA, MS, M.Eng., MBA, etc.)','Master')\n",
    "ed_pandas['EdLevel'] = ed_pandas['EdLevel'].replace('Other doctoral degree (Ph.D, Ed.D., etc.)','Doctor')\n",
    "\n",
    "ed_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"EdLevel\", y=\"WorkWeekHrs\", data=ed_pandas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narysuj wykres boxplot pokazujacy rozklad dochodów w zależności od wykształcenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "ed_level = spark.sql(f\"select EdLevel, cast (CompTotal as int) as CompTotal from {table_name} \\\n",
    "            where cast(CompTotal as int) between 0 and 1000000  \\\n",
    "            and (EdLevel like '%Bachelor%' or EdLevel like '%Master%' or EdLevel like '%Other doctoral%')\")\n",
    "\n",
    "ed_pay = ed_level.toPandas()\n",
    "ed_pay['EdLevel'] = ed_pay['EdLevel'].replace('Bachelor’s degree (BA, BS, B.Eng., etc.)','Bachelor')\n",
    "ed_pay['EdLevel'] = ed_pay['EdLevel'].replace('Master’s degree (MA, MS, M.Eng., MBA, etc.)','Master')\n",
    "ed_pay['EdLevel'] = ed_pay['EdLevel'].replace('Other doctoral degree (Ph.D, Ed.D., etc.)','Doctor')\n",
    "\n",
    "ed_pay.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"EdLevel\", y=\"CompTotal\", kind=\"boxen\",\n",
    "            data=ed_pay);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narysuj wykres wiolinowy pokazujacy rozklad dochodów w zależności od wykształcenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "ed_level = spark.sql(f\"select EdLevel, Gender, cast (CompTotal as int) as CompTotal from {table_name} \\\n",
    "            where cast(CompTotal as int) between 1000 and 500000  \\\n",
    "            and gender in ('Man', 'Woman') \\\n",
    "            and (EdLevel like '%Bachelor%' or EdLevel like '%Master%' or EdLevel like '%Other doctoral%')\")\n",
    "\n",
    "ed_pay = ed_level.toPandas()\n",
    "ed_pay['EdLevel'] = ed_pay['EdLevel'].replace('Bachelor’s degree (BA, BS, B.Eng., etc.)','Bachelor')\n",
    "ed_pay['EdLevel'] = ed_pay['EdLevel'].replace('Master’s degree (MA, MS, M.Eng., MBA, etc.)','Master')\n",
    "ed_pay['EdLevel'] = ed_pay['EdLevel'].replace('Other doctoral degree (Ph.D, Ed.D., etc.)','Doctor')\n",
    "\n",
    "ed_pay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narysuj wykres pokazujacy rozklad dochodów w zależności od wyksztalcenia i płci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(f\"select Age, DevType, cast (ConvertedComp as int) as ConvertedComp \\\n",
    "            from {table_name} \\\n",
    "            where cast(ConvertedComp as int) between 0 and 300000 \\\n",
    "            and DevType is not null\").toPandas()\n",
    "\n",
    "df['DS'] = df['DevType'].apply(lambda x: 1 if 'Data scientist' in x else 0)\n",
    "df['AR']=df['DevType'].apply(lambda x: 1 if 'Academic researcher' in x else 0)\n",
    "df['MGR']=df['DevType'].apply(lambda x: 1 if 'anager' in x else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"EdLevel\", y=\"CompTotal\", hue=\"Gender\", kind=\"violin\", split=True, data=ed_pay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"ConvertedComp\", y=\"Age\", hue='AR', data=df ,alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"ConvertedComp\", y=\"Age\", hue='MGR', data=df ,alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select distinct DevType from survey\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_v = spark.sql(\"select SOVisitFreq, country, count (*) as cnt from survey \\\n",
    "            where country is not null and SOVisitFreq is not null \\\n",
    "            and country in ('Poland', 'United States', 'Russian Federation', 'China', 'India') \\\n",
    "            group by country, SOVisitFreq\").toPandas()\n",
    "so_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap2_data = pd.pivot_table(so_v, values='cnt', index=['country'], columns='SOVisitFreq')\n",
    "sns.heatmap(heatmap2_data, cmap=\"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narysuj heatmape odwiedzin na StackOverflow dla wybranych krajów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select distinct SOVisitFreq from survey\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_v = spark.sql(\"select SOVisitFreq, t1.country, count(*)/first(t2.t) as cnt from survey t1 \\\n",
    "            join (select country, count(*) as t from survey group by country) t2 \\\n",
    "            on t1.country = t2.country \\\n",
    "            where t1.country is not null and SOVisitFreq is not null \\\n",
    "            and t1.country in ('Poland', 'United States', 'Russian Federation', 'China', 'India', 'Germany', 'Japan') \\\n",
    "            group by t1.country, SOVisitFreq\").toPandas()\n",
    "\n",
    "so_v['SOVisitFreq'] = pd.Categorical(so_v['SOVisitFreq'], [\"I have never visited Stack Overflow (before today)\", \"Less than once per month or monthly\", \"A few times per month or weekly\", \"A few times per week\", \"Daily or almost daily\", \"Multiple times per day\"])\n",
    "# so_v.sort_values['SOVisitFreq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap2_data = pd.pivot_table(so_v, values='cnt', index=['country'], columns='SOVisitFreq')\n",
    "sns.heatmap(heatmap2_data, cmap=\"BuGn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "notebook_test": {
   "keytab_path": "/data/work/home/ds-lab-testuser1/ds-lab-testuser1.keytab",
   "user": "ds-lab-testuser1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
