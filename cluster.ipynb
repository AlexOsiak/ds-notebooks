{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zajęcia 1.\n",
    "\n",
    "Zakres:\n",
    "* zapoznanie sie z 2 srodowiskami pracy (klaster Hadoop oraz środowisko dostepne na GCP.\n",
    "* operacje na rozproszonym i obiektowym systemie plików (HDFS i GCS)\n",
    "* wykorzystanie platformy Apache Spark\n",
    "\n",
    "Języki:\n",
    "* bash, python, sql\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krótka lista przydatnych poleceń bash:\n",
    "\n",
    "https://www.reddit.com/r/linux/comments/9rns12/some_linux_commands_cheatsheet/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL Jupyter na klastrze Instytutu Informatyki: https://zsibio.ii.pw.edu.pl/jupyter/\n",
    "\n",
    "\n",
    "## Klaster Hadoop\n",
    "\n",
    "edge node: cdh00 (węzeł dostępowy)\n",
    "\n",
    "HDFS:\n",
    "name node: cdh01\n",
    "data nodes: cdh02-cdh05\n",
    "\n",
    "YARN\n",
    "resource manager: cdh01\n",
    "node managers: cdh02-cdh05\n",
    "\n",
    "konsola administracyjna: http://cdh01:8080/\n",
    "\n",
    "Dystrybucja Hadoop: Hortonworks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Jupyter Notebook\n",
    "\n",
    "Interaktywny notatnik dostepny poprzez przeglądarkę.\n",
    "Służy do wpisywania poleceń w wybranych jezykach programowania oraz opis w tzw jezyku markdown.\n",
    "Tryb edycji + tryb poleceń. \n",
    "Podstawowe skróty klawiaturowe: \n",
    "* Esc/Enter\n",
    "* strzalki\n",
    "* ctrl-enter/shift-enter\n",
    "* a/b/d\n",
    "* y/m \n",
    "* znaczenie ! oraz %%\n",
    "Notatnik zapisywany jest w formacie ipynb (IPythonNoteBook)\n",
    "\n",
    "Kolejnosc uruchomienia moze byc rozna.\n",
    "Mozliwosc zatrzymania kernela i uruchomienia od nowa. \n",
    "\n",
    "Polecamy film: https://www.youtube.com/watch?v=HW29067qVWk\n",
    "\n",
    "\n",
    "\n",
    "### Security\n",
    "Klaster jest zabezpieczony przed niepowolanym dostepem.\n",
    "Zazwyczaj dostep do klastra to: zalogowanie poprzez ssh do wezla dostepowego a potem wykonywanie polecen. \n",
    "My logujemy sie do Jupytera, w tle pobierany jest ticket dostepowy do odpowiednich zasobów klastra. Korzystajac ze zmiennych srodowiskowych i plikow konfiguracyjnych Jupyter wie jak polaczyc sie z menedzerem zasobow oraz namenodem HDFS.\n",
    "\n",
    "Dostep do Jupyter jest publiczny i po zajeciach mozna z niego korzystac.\n",
    "\n",
    "\n",
    "## Praca z rozproszonym systemem plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user_name = os.environ.get('USER')\n",
    "print(user_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kopiowanie danych do swojego HOME\n",
    "\n",
    "W katalogu `/data/local/datascience/data/` znajduje sie plik który bedzie nam dzisiaj słuzyl do pracy. Należy go skopiować do swojego katalogu domowego. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd \n",
    "mkdir -p data\n",
    "cd data\n",
    "cp /data/local/datascience/data/brca.txt .\n",
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head data/brca.txt\n",
    "echo\n",
    "tail data/brca.txt\n",
    "echo\n",
    "wc -l data/brca.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDFS\n",
    "Do tej pory korzystalismy z lokalnego systemu plików do ktorego ma dostep maszyna na ktora sie zalogowalismy (cdh00). Teraz zaczniemy korzystac z rozproszonego systemu plikow.\n",
    "\n",
    "Dla podstawowych polecen systemowych na plikach istnieja odpowiedniki polecen dla systemu HDFS\n",
    "* `ls` -> `hdfs dfs -ls`\n",
    "* `cp` -> `hdfs dfs -cp`\n",
    "* `mv` -> `hdfs dfs -mv`\n",
    "* `rm` -> `hdfs dfs -rm`\n",
    "\n",
    "Pełna lista poleceń znajduje się na www: https://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-common/FileSystemShell.html\n",
    "\n",
    "### Listowanie swojego HOME na HDFS\n",
    "Każdy ma swoj katalog domowy na HDFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swoj katalog mozna tez sprawdzic podajac sciezke bezwgledna od katalogu glownego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /user/${USER}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzmy katalog glowny na HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZADANIE 1\n",
    "Korzystajac z analogii do polecen znanych z lokalnego sytemu pliku oraz z dokumentacji polecen dla HDFS stworz na HDFS katalog external a w nim katalog data w swoim podkatalogu domowym. Sprawdz foldery istnieją."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -mkdir -p /user/${USER}/external/data 2>/dev/null\n",
    "hdfs dfs -ls -R /user/${USER}/external/ 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodanie pliku na HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -put data/brca.txt /user/${USER}/external/data\n",
    "hdfs dfs -ls /user/${USER}/external/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaki jest rozmiar pliku? Mozna skorzystac z przelacznika -h w ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls -h /user/${USER}/external/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A calkowita wielkosc pliku? Polecenie `du`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -du -h /user/${USER}/external/data/brca.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informacje o statusie pliku: polecenie `fsck`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs fsck /user/${USER}/external/data/brca.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plik mozna rowniez odczytac bezposrednio z HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -cat /user/${USER}/external/data/brca.txt | head "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZADANIE 2\n",
    "W swoim katalogu domowym stworz katalog external/temp. Skopiuj do niego plik brca.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -mkdir -p /user/${USER}/external/temp\n",
    "hdfs dfs -cp /user/${USER}/external/data/brca.txt /user/${USER}/external/temp\n",
    "hdfs dfs -ls /user/${USER}/external/temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usuwanie i odzyskiwanie plikow\n",
    "\n",
    "Do usuwanie sluzy polecenie -rm. Domyslnie usuwany plik jest przesuwany do kosza, skad mozna go odzyskac. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -rm /user/${USER}/external/temp/brca.txt\n",
    "hdfs dfs -ls /user/${USER}/external/temp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dostalismy lokalizacje pliku z kosza, stamtad mozemy go skopiowac."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do samodzielnej weryfikacji:\n",
    "* Przywrócenie pliku z kosza\n",
    "* Zachowanie polecenia rm przy podaniu parametru `skipTrash`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmiana uprawnień na katalogu/pliku\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -chmod -R 747 /user/${USER}/external/data/\n",
    "hdfs dfs -ls /user/${USER}/external/data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobranie pliku z powrotem na lokalny dysk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -get /user/${USER}/external/data/brca.txt brca2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark\n",
    "podłączenie się do klastra Sparkowego\n",
    "stworzenie tabeli z pliku CSV\n",
    "zapytania SQL na tabelach (SparkSQL)\n",
    "Na tych cwiczeniach bedziemy korzystac z pliku ktory zapisalismy na HDFS w pierwszej czesci cwicczenia.\n",
    "\n",
    "Sprawdzmy czy plik znajduje się na swoim miejscu w katalogu: /user/${USER}/external/data\n",
    "\n",
    "TODO - dalabym przyklad recznego stworzenia DF. Potem stworzenie DF na podstawie danych (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /user/${USER}/external/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losujemy numer portu. Domyslnie port na ktorym Spark wystawia swoj interfejs graficzny jest 4040. zeby nie zajmowac sobie wzajmnie numerow portu - wykonamy losowanie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user_name = os.environ.get('USER')\n",
    "print(user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "ui_port = random.randint(4000,4999)\n",
    "print(ui_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".master('yarn-client') \\\n",
    ".config('spark.driver.memory','1g') \\\n",
    ".config('spark.executor.memory', '2g') \\\n",
    ".config('spark.ui.port',f'{ui_port}') \\\n",
    ".appName(f'ds-{user_name}') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych\n",
    "Będziemy wykonywać analizę na danych z https://gdac.broadinstitute.org/ zawierajacych dane z badani nad CNV w obrebie BRAC2. Ściągniety plik znajduje sie w hdfs://edugen/brca.txt TODO\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'/user/{user_name}/external/data/brca.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(path, format=\"csv\", sep=\"\\t\", inferSchema=\"true\", header=\"true\")\n",
    "\n",
    "# df.registerTempTable(f\"{table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()\n",
    "df.count() # wymiary\n",
    "len(df.columns) # wymiary\n",
    "df.head (5) # check\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"Sample\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chrom = df.select(\"Chromosome\").distinct()\n",
    "df_chrom.count()\n",
    "df.filter(df.Chromosome > 21).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cached.groupBy(\"Chromosome\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cached.groupBy(\"Sample\",\"Chromosome\").count().orderBy(asc(\"Sample\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs://bdg-la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przeniesienie pliku na GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp ~/ds-notebooks/README.md gs://bdg-lab-$USER  # upload obiektu do kubełka"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notebook_test": {
   "keytab_path": "/data/work/home/ds-lab-testuser1/ds-lab-testuser1.keytab",
   "user": "ds-lab-testuser1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
